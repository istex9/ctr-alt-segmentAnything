{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Data exploration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb468d135a10fa6c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Import necessary libraries for data exploration\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "997b298148eae1ed",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explore dataset containing segmentation masks\n",
    "df_masks = pd.read_csv('train_ship_segmentations_v2.csv')\n",
    "df_masks.head()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Add a column to indicate if an image has ships\n",
    "df_masks['has_ship'] = df_masks['EncodedPixels'].notnull()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5aa6d810d1de697f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Dimension of images\n",
    "image = plt.imread(f\"train_v2/{df_masks['ImageId'].iloc[0]}\")\n",
    "width = image.shape[0]\n",
    "height = image.shape[1]\n",
    "print(f\"Width: {width}, Height: {height}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d802e39dd7ed452",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Count the number of images, the number with ships, and calculate the ratio\n",
    "num_images_total = df_masks['ImageId'].nunique()\n",
    "num_images_with_ships = df_masks[df_masks['EncodedPixels'].notna()]['ImageId'].nunique()\n",
    "num_images_without_ships = num_images_total - num_images_with_ships\n",
    "ratio_ship_no_ship = num_images_with_ships / num_images_without_ships if num_images_without_ships != 0 else float('inf')\n",
    "\n",
    "print(f\"Total number of images: {num_images_total}\")\n",
    "print(f\"Number of images with ships: {num_images_with_ships}\")\n",
    "print(f\"Number of images without ships: {num_images_without_ships}\")\n",
    "print(f\"Ratio of images with ships to without ships: {ratio_ship_no_ship:.2f}\")\n",
    "df_masks.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4182f33d77bbb583",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape=(width, height)):\n",
    "    \"\"\"\n",
    "    Decodes a run-length encoded (RLE) mask string into a 2D binary mask array.\n",
    "\n",
    "    Run-Length Encoding (RLE) is a compact representation of binary masks.\n",
    "    The mask is represented as pairs of start and length values, indicating the \n",
    "    consecutive pixels that should be set to 1 (foreground) in an otherwise zero \n",
    "    (background) mask.\n",
    "    \"\"\"\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0::2], s[1::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2dff446df891b117",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_images = 5\n",
    "plt.figure(figsize=(10, 20))\n",
    "\n",
    "# Get unique image IDs to display\n",
    "unique_image_ids = df_masks['ImageId'].unique()[:num_images]\n",
    "\n",
    "for i, image_id in enumerate(unique_image_ids):\n",
    "    # Select all Run-Length Encoding (RLE) masks for the current image\n",
    "    image_rles = df_masks[df_masks['ImageId'] == image_id]['EncodedPixels'].values\n",
    "    has_ship = df_masks[df_masks['ImageId'] == image_id]['has_ship'].values[0]  # Check if it has a ship\n",
    "\n",
    "    # Load the original image from the training dataset (train_v2 folder)\n",
    "    image_path = f\"train_v2/{image_id}\"\n",
    "    image = plt.imread(image_path)  # Load the original image\n",
    "\n",
    "    # Initialize an empty mask\n",
    "    combined_mask = np.zeros((width, height), dtype=np.uint8)\n",
    "\n",
    "    # Decode each RLE and combine the masks\n",
    "    for rle in image_rles:\n",
    "        if pd.notna(rle):  # If RLE is not NaN, decode it\n",
    "            combined_mask |= rle_decode(rle, shape=(width, height))  # Combine masks using logical OR\n",
    "\n",
    "    # Display the original image\n",
    "    plt.subplot(num_images, 2, 2 * i + 1)  # Two columns: original image on the left\n",
    "    plt.imshow(image)  # Display the original image\n",
    "    plt.title(f\"Original Image {i + 1}\")  # Title for the original image\n",
    "    plt.axis('off')  # Remove axis for a cleaner display\n",
    "\n",
    "    # Display the combined mask\n",
    "    plt.subplot(num_images, 2, 2 * i + 2)  # Two columns: mask on the right\n",
    "    plt.imshow(combined_mask, cmap='gray')  # Show the mask in grayscale\n",
    "    plt.title(f\"Combined Mask {i + 1}\")  # Title for each mask\n",
    "    plt.xlabel(f\"has_ship = {has_ship}\")  # Add text below indicating if the image has a ship\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "941f31ddc0c7bd4e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Creating training and validation datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15d3f5dbb4bdf1fe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms.functional as TF"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64f5e43afacbfd2f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ShipDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transforms=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "        self.image_ids = df['ImageId'].unique()\n",
    "        self.imageid_to_mask = self._generate_image_mask_map()\n",
    "        \n",
    "    def _generate_image_mask_map(self):\n",
    "        imageid_to_mask = {}\n",
    "        for img_id in self.image_ids:\n",
    "            records = self.df[self.df['ImageId'] == img_id]\n",
    "            masks = records['EncodedPixels'].tolist()\n",
    "            imageid_to_mask[img_id] = masks\n",
    "        return imageid_to_mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.image_ids[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_id)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # Get all masks for this image\n",
    "        masks = self.imageid_to_mask[img_id]\n",
    "        mask = np.zeros((768, 768), dtype=np.uint8)\n",
    "        for m in masks:\n",
    "            if isinstance(m, str):\n",
    "                mask += rle_decode(m)\n",
    "        mask = Image.fromarray(mask)\n",
    "        \n",
    "        if self.transforms:\n",
    "            image, mask = self.transforms(image, mask)\n",
    "        \n",
    "        return image, mask"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "463fe0daefa361a4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def transforms(image, mask):\n",
    "    # Resize images and masks\n",
    "    resize_size = (256, 256)\n",
    "    image = image.resize(resize_size, resample=Image.BILINEAR)\n",
    "    mask = mask.resize(resize_size, resample=Image.NEAREST)\n",
    "    \n",
    "    # Random horizontal flip\n",
    "    if np.random.rand() > 0.5:\n",
    "        image = TF.hflip(image)\n",
    "        mask = TF.hflip(mask)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    image = TF.to_tensor(image)\n",
    "    mask = torch.from_numpy(np.array(mask)).unsqueeze(0).float()\n",
    "    return image, mask"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba85f765cb1db145",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "img_dir = 'train_v2/'\n",
    "dataset = ShipDataset(df_masks, img_dir=img_dir, transforms=transforms)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2d5527d19586c23",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a mapping from image_id to has_ship label\n",
    "imageid_to_has_ship = df_masks.groupby('ImageId')['has_ship'].any().to_dict()\n",
    "\n",
    "# Get lists of indices for images with and without ships\n",
    "with_ship_indices = []\n",
    "without_ship_indices = []\n",
    "\n",
    "for idx, img_id in enumerate(dataset.image_ids):\n",
    "    if imageid_to_has_ship[img_id]:\n",
    "        with_ship_indices.append(idx)\n",
    "    else:\n",
    "        without_ship_indices.append(idx)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa62508db56cc468",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split indices for images with ships\n",
    "train_with_ship_indices, val_with_ship_indices = train_test_split(\n",
    "    with_ship_indices,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split indices for images without ships\n",
    "train_without_ship_indices, val_without_ship_indices = train_test_split(\n",
    "    without_ship_indices,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combine train and validation indices\n",
    "train_indices = train_with_ship_indices + train_without_ship_indices\n",
    "val_indices = val_with_ship_indices + val_without_ship_indices\n",
    "\n",
    "# Shuffle indices\n",
    "np.random.shuffle(train_indices)\n",
    "np.random.shuffle(val_indices)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a1993c668196ad9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfdb35ab913d98d1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_train_images = len(train_dataset)\n",
    "print(f\"Number of training images: {num_train_images}\")\n",
    "\n",
    "num_val_images = len(val_dataset)\n",
    "print(f\"Number of validation images: {num_val_images}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b17a5e4404f74982",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def display_random_sample(dataset):\n",
    "    # Get a random index\n",
    "    random_idx = random.randint(0, len(dataset) - 1)\n",
    "\n",
    "    # Retrieve the image and mask\n",
    "    image, mask = dataset[random_idx]\n",
    "\n",
    "    # Convert tensors to NumPy arrays\n",
    "    image_np = image.permute(1, 2, 0).numpy()\n",
    "    mask_np = mask.squeeze().numpy()\n",
    "\n",
    "    # Display\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    ax[0].imshow(image_np)\n",
    "    ax[0].set_title('Image')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].imshow(mask_np, cmap='gray')\n",
    "    ax[1].set_title('Mask')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c43915e7e4f800a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "display_random_sample(val_dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "119fc6ee48ea8e14",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fc4349ee569a06d3"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7947897d403d1317"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
